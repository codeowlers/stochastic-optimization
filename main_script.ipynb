{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gurobipy as gp\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables to be used to generate nodes and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Number of nodes\n",
    "n = 200\n",
    "# Number of clusters\n",
    "p = 2\n",
    "\n",
    "capacity_mean = 10\n",
    "capacity_stddev = 2\n",
    "weight_mean = 1\n",
    "weight_stddev = 0.1\n",
    "lambda_param = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Random Instances using capacity mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_instances(n, p, capacity_mean, capacity_stddev):\n",
    "    # Generate 2D positions for n nodes\n",
    "    nodes = np.random.rand(n, 2)\n",
    "\n",
    "    # Generate capacities for clusters\n",
    "    capacities = np.random.normal(capacity_mean, capacity_stddev, p)\n",
    "\n",
    "    return nodes, capacities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Random Weights using weight mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_weights(n, weight_mean, weight_stddev):\n",
    "    # Generate weights for n nodes\n",
    "    weights = np.random.normal(weight_mean, weight_stddev, n)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Euclidean distance between two points p and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p, q):\n",
    "    return np.sqrt(np.sum((p-q)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_ccp(nodes, capacities, weights, lambda_param):\n",
    "    start = time.time()\n",
    "    n = nodes.shape[0]\n",
    "    p = len(capacities)\n",
    "\n",
    "    # Create gurobi model\n",
    "    model = gp.Model('ccp')\n",
    "\n",
    "    # Create decision variables\n",
    "    x = {}\n",
    "    y = {}\n",
    "\n",
    "    # Update decision variables as mentioned in the problem statement\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            x[i, j] = model.addVar(vtype=gp.GRB.BINARY, name=f'x[{i},{j}]')\n",
    "        y[i] = model.addVar(vtype=gp.GRB.BINARY, name=f'y[{i}]')\n",
    "\n",
    "    # Set objective function\n",
    "    obj = gp.quicksum(euclidean_distance(nodes[i], nodes[j]) * x[i,j] for i in range(n) for j in range(p))\n",
    "    obj += lambda_param * gp.quicksum(capacities[j]*y[j] for j in range(p))\n",
    "    obj -= lambda_param * gp.quicksum(weights[i]*x[i,j] for i in range(n) for j in range(p))\n",
    "    model.setObjective(obj, gp.GRB.MINIMIZE)\n",
    "\n",
    "    # Add constraints\n",
    "    for i in range(n):\n",
    "        model.addConstr(gp.quicksum(x[i,j] for j in range(p)) == 1, name=f'assign[{i}]')\n",
    "\n",
    "    model.addConstr(gp.quicksum(y[j] for j in range(p)) <= p, name='num_clusters')\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            model.addConstr(x[i,j] <= y[j], name=f'x_c[{i},{j}]')\n",
    "\n",
    "    # Solve model\n",
    "    model.optimize()\n",
    "    # Extract solution\n",
    "    clusters = []\n",
    "    for j in range(p):\n",
    "        cluster = [i for i in range(n) if x[i,j].X > 0.5]\n",
    "        clusters.append(cluster)\n",
    "    end = time.time()\n",
    "    return clusters, end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(clusters_1, clusters_2):\n",
    "    jaccard_scores = []\n",
    "    for cluster_1 in clusters_1:\n",
    "        jaccard_scores_per_cluster = []\n",
    "        for cluster_2 in clusters_2:\n",
    "            union = len(set(cluster_1).union(cluster_2))\n",
    "            intersection = len(set(cluster_1).intersection(cluster_2))\n",
    "            jaccard_index = intersection / union\n",
    "            jaccard_scores_per_cluster.append(jaccard_index)\n",
    "        jaccard_scores.append(max(jaccard_scores_per_cluster))\n",
    "    return np.mean(jaccard_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_index(clusters_1, clusters_2):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    n = len(clusters_1)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if (clusters_1[i] == clusters_1[j] and clusters_2[i] == clusters_2[j]):\n",
    "                tp += 1\n",
    "            elif (clusters_1[i] != clusters_1[j] and clusters_2[i] != clusters_2[j]):\n",
    "                tn += 1\n",
    "            elif (clusters_1[i] == clusters_1[j] and clusters_2[i] != clusters_2[j]):\n",
    "                fp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "    return (tp + tn) / (tp + tn + fp + fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insample_stability(clusters_reference,nodes, capacities, weights, lambda_param, num_runs=100):\n",
    "    jaccard_scores = []\n",
    "    for i in range(num_runs):\n",
    "        clusters, _ = solve_ccp(nodes, capacities, weights, lambda_param)\n",
    "        jaccard_scores.append(jaccard_similarity(clusters, clusters_reference))\n",
    "    return np.mean(jaccard_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(nodes, weights, train_ratio=0.7):\n",
    "    n = nodes.shape[0]\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices = indices[:int(n * train_ratio)]\n",
    "    val_indices = indices[int(n * train_ratio):]\n",
    "    return nodes[train_indices], weights[train_indices], nodes[val_indices], weights[val_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_sample_stability(num_runs=10):\n",
    "    rand_index_scores = []\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "\n",
    "        nodes, capacities = generate_instances(n, p, capacity_mean, capacity_stddev)\n",
    "        weights = generate_weights(n, weight_mean, weight_stddev)\n",
    "        \n",
    "        nodes_train, weights_train, nodes_val, weights_val = split_data(nodes, weights)\n",
    "        \n",
    "        clusters_train,_ = solve_ccp(nodes_train, capacities, weights_train, lambda_param)\n",
    "        clusters_val,_ = solve_ccp(nodes_val, capacities, weights_val, lambda_param)\n",
    "        rand_index_scores.append(rand_index(clusters_train, clusters_val))\n",
    "    return np.mean(rand_index_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_cluster_nodes(nodes, capacities, weights):\n",
    "    start = time.time()\n",
    "    n = nodes.shape[0]\n",
    "    p = len(capacities)\n",
    "\n",
    "    # Create a list to store the clusters\n",
    "    clusters = [[] for _ in range(p)]\n",
    "\n",
    "    # Create a list to store the remaining capacities of each cluster\n",
    "    remaining_capacities = capacities.copy()\n",
    "\n",
    "    # Sort the nodes by their weights in descending order\n",
    "    node_weights = [(node, weight) for node, weight in enumerate(weights)]\n",
    "    node_weights.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Greedily assign each node to a cluster with enough capacity\n",
    "    for node, weight in node_weights:\n",
    "        for j in range(p):\n",
    "            if remaining_capacities[j] >= weight:\n",
    "                clusters[j].append(node)\n",
    "                remaining_capacities[j] -= weight\n",
    "                break\n",
    "    end = time.time()\n",
    "    # Return the list of clusters, each represented by a list of node indices\n",
    "    return clusters, end - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate 2D nodes and random capacities for clusters\n",
    "nodes, capacities = generate_instances(n, p, capacity_mean, capacity_stddev)\n",
    "# Generate random weight for each node\n",
    "weights = generate_weights(n, weight_mean, weight_stddev)\n",
    "\n",
    "clusters, time1 = solve_ccp(nodes, capacities, weights, lambda_param)\n",
    "\n",
    "greedy_clusters, time2 = greedy_cluster_nodes(nodes, capacities, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_sample_stability_score = insample_stability(clusters,nodes, capacities, weights, lambda_param, num_runs=100)\n",
    "# print(\"Insample Stability:\",in_sample_stability_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# out_sample_stability_score = out_sample_stability(num_runs=100)\n",
    "# print(\"Outsample Stability:\",out_sample_stability_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "35f5253ae318fcd12f4d0d917d7d23cb64d01e924a6e8f0f585e0ccb777f4db3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
